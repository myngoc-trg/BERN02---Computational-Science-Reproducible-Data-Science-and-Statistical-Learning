{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cf96e3-0378-44b3-adda-f751a3cb3027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "#the datasets\n",
    "import sklearn.datasets\n",
    "import sklearn.cluster\n",
    "\n",
    "#For better statistical plotting\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec3efcd-387e-4d5c-8e10-290800a7c212",
   "metadata": {},
   "source": [
    "# Using SVD and PCA to reduce dimensions\n",
    "\n",
    "We will use the iris dataset that is included in the sklearn package and convert the basic data in it to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf558da-c261-4043-a26a-c8362f153fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sklearn.datasets.load_iris()\n",
    "df_iris = pd.DataFrame(iris.data, columns=iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8b166d-6398-4cca-9fbd-ca4c34df3eb0",
   "metadata": {},
   "source": [
    "## Task\n",
    " \n",
    " * investigate what iris contains by reading print(iris['DESCR'])\n",
    " * and investigate the structure of the data in the dataframe with describe() and by looking at the head of the DataFrame\n",
    " * Use the \"pairplot\" from seaborn to investigate the relation between the data, can you by eye discover correlation between the different type of data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bab4e1-d3ce-41b3-8906-cfed3ce7a9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1617a432-9999-43e2-b5df-3213ab82db6c",
   "metadata": {},
   "source": [
    "Singular value decomposition factorizes matrix <br>\n",
    "$X \\in mxn$ <br> into <br> $X = U \\, * \\, \\sum \\, * \\, V^T$ <br>\n",
    "Where:\n",
    "\n",
    "* $U \\in m×m$ that is called the left singular vectors where each columns is a orthonormal eigenvectors of $XX^T$\n",
    "* the diagonal matrix  Σ with entries single entries $\\in  \\mathbb{R}$ that are the non-negative singular values of  X\n",
    "* and the right singular vectors in Matrix $V \\in n×n$ where the columns are the set of orthonormal eigenvectors of  $X^TX$\n",
    "\n",
    "\n",
    "The SVD algorithm from the numpy package can calculate this quite efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d196f86-fea5-4e33-aaa0-e65e24fca81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_iris, S_iris, Vt_iris = np.linalg.svd(df_iris, full_matrices=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6478a09-48ce-4872-b50a-f1bcb85f8165",
   "metadata": {},
   "source": [
    "## Task\n",
    "Plot the cummulative sum of the entries in $S_{iris}^2$ divided by the sum of $S_{iris}^2$ and use the equations 12.8 and 12.9 in the book to label the axis. what is the sum of $S_{iris}^2$? use the answer to label the points in legend of this plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74262798-3690-4896-8c4c-5cb085f05080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e3666b-7d26-4397-87dc-18c11dbc8962",
   "metadata": {},
   "source": [
    "## Task\n",
    "Label the axis in the following plot. It seems as the SVD has selected a vector in which the data is well separated. Try the other vectors and see if you can find other vectors that separate the different flowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c0c265-5668-4561-9311-d78f06f3858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,2,figsize=(12,6))\n",
    "selector=iris['target']\n",
    "\n",
    "for i in np.unique(selector):\n",
    "    selector_name=iris['target_names'][i]\n",
    "    ax[0].scatter(U_iris[selector==i,0],U_iris[selector==i,1],label=selector_name)\n",
    "    ax[1].scatter(df_iris.iloc[selector==i,0],df_iris.iloc[selector==i,1],label=selector_name)\n",
    "[ax[a].legend() for a in range(2)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894080ff-3be2-4add-891d-05177a0c9ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fed419f-2609-4e3d-9ca7-d698296c261d",
   "metadata": {},
   "source": [
    "### Illustration of SVD\n",
    "To better understand the effect of SVD we will look at a simplified dataset and normalize the data.\n",
    "Then we will simplify and illustrate the calculation of the projection onto the axis we will rotate the axis system and use the y-value as perpendicular projection $z_i$ in formula 12.5 or figure 12.2 in the book.\n",
    "\n",
    "## Task\n",
    "\n",
    "* create a new DataFrame with the petal length and width that only contains the varieties 'versicolor' and 'virginica'\n",
    "* centralize each of the axis (subtract the mean) and normalize the scale (divide by the variance)\n",
    "* make a scatterplot between the normalized petal length and width.matrix}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f991bc85-0898-40a7-bac5-6bbd04ff9a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c977469-a6ad-453f-8b3e-073c3a28c5f0",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "Create a composite figure with a few plots in each of which you rotate the axis by an angle $\\alpha$. The coordinates can be understood as:\n",
    "  <br> x=r cos($\\alpha$) and y=r sin($\\alpha$) <br>\n",
    "  So the rotation of around the center we can express as:<br>\n",
    "  $$ \\begin{bmatrix} x' \\\\ y' \\end{bmatrix} = \\begin{bmatrix} cos(\\alpha) & sin(\\alpha) \\\\-sin(\\alpha) & cos(\\alpha)\\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bd23f1-373a-41f6-a62a-8c2337dfc79f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01e92d68-8ad5-4a95-a5c5-51688b58d87a",
   "metadata": {},
   "source": [
    "## Task \n",
    "\n",
    "The y-value of each point corresponds to the $z_i$ value or the value that is not explained by the vector we assume here that for the perfect vector the euclidian distance is the same as the y-value. <br> The sum of the squared values corresponds to the variance that is not explained by the vector and that is to be minimized. The x-values (after rotation) correspond to the value of the variance that is explained by the first independent vector. For an $\\alpha$ from 0 to 360 plot the sum of the squared y-values against the angle. With matplotlib this can e.g. be achieved with:\n",
    "\n",
    "```\n",
    "    fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "    ax.plot(alpha, r)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63f0140-80bd-4dda-88a3-58079ba6d6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1a60497-791b-4596-809a-2d1ec71c82c4",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "Finally compare if the minimum values of this plot and the vector that you get back for the a new SVD are comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9742b11-3c46-478e-87ac-07ff4fb76c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bc0c0a3-f64d-42ec-94c3-54ed5e86359c",
   "metadata": {},
   "source": [
    "# Limitations of SVD/PCA\n",
    "It is a fair assumption to consider PCA a non normallized version of SVD (check the math) however there are other that this part of the lab shall reveal. SVD is often used to look at measured (discrete) data and extract the normalized vectors from it. Here we shall first construct known data and then try to retrieve the data in it. We use for this we construct a sequence of non overlapping spectra of different species and look at the progression of the kinetic:<be>\n",
    "WE excite the ground state of the same (excitation is before the space of observation) and then see the components A, B, C decay back into the ground state<br>\n",
    "GS -> A-> B-> C -> GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2927540-3bf7-4b5f-b6ea-20a93ecd19a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss = lambda x,mu,sigma=50: np.exp(-((x-mu)/sigma)**2)\n",
    "x=np.arange(300,800,1)\n",
    "spectra=pd.DataFrame({'A':gauss(x=x,mu=400),'B':gauss(x=x,mu=600),'C':gauss(x=x,mu=700),'GS':gauss(x=x,mu=500)},index=x)\n",
    "spectra.index.name='wavelength in nm'\n",
    "time=np.logspace(-2,4,int(1e4))\n",
    "c=np.zeros((len(time),3))\n",
    "rates=[1/0.1,1/10,1/1000]\n",
    "c[0,0]=1\n",
    "for i,t in enumerate(time[1:]):\n",
    "    dc=c[i,:]\n",
    "    timestep=t-time[i]\n",
    "    dc[0]+=-rates[0]*timestep*dc[0]\n",
    "    dc[1]+=rates[0]*timestep*dc[0]-rates[1]*timestep*dc[1]\n",
    "    dc[2]+=rates[1]*timestep*dc[1]-rates[2]*timestep*dc[2]\n",
    "    dc[dc<0]=0\n",
    "    c[i+1,:]=dc\n",
    "c=pd.DataFrame(c,index=time,columns=['A','B','C'])\n",
    "c['GS']=-1*c.sum(axis=1)\n",
    "c.index.name='time in ps'\n",
    "data=0\n",
    "for i,col in enumerate(c.columns):\n",
    "    A,B=np.meshgrid(c.loc[:,col].values,spectra.loc[:,col].values)\n",
    "    C=pd.DataFrame((A*B).T,index=c.index)\n",
    "    if i==0: data=C\n",
    "    else: data=data+C\n",
    "data.columns=spectra.index.values\n",
    "\n",
    "fig,ax=plt.subplots(1,3,figsize=(14,4))\n",
    "spectra.plot(ax=ax[0])\n",
    "c.plot(ax=ax[1])\n",
    "ax[1].set_xscale('log')\n",
    "X, Y = np.meshgrid(data.columns.values.astype(float), data.index.values.astype(float))\n",
    "ax[2].pcolormesh(X,Y,data.values,cmap='jet')\n",
    "ax[2].set_yscale('log')\n",
    "ax[2].set_xlabel(spectra.index.name)\n",
    "ax[2].set_ylabel(c.index.name)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4126cd40-582e-4be2-9f98-fb596cc648fb",
   "metadata": {},
   "source": [
    "## Task\n",
    "Use SVD on the DataFrame \"data\" just generated, plot the plot the spectra, the kinetics and the strength of the first 5 singular vectors in this data. why are they different? Any idea how you would fix that?<br>Hint: Check that you have the right orientation of the matrics by comparing the dimensions to the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd90745-53b2-4add-84b8-5a16caa61485",
   "metadata": {},
   "outputs": [],
   "source": [
    "#**code**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dc20ec-1d1f-4566-8523-6e1a083b7548",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "In this lab we will look into both K-mean clustering and hierachical clustering. <br>\n",
    "please use the **df_iris** from above for these plots.\n",
    "\n",
    "## K-Mean clustering\n",
    "\n",
    "Use the below code to create a plot with 5 rows and 5 columns. Now use sklearn.cluster.KMeans to calculate a new \"selector\" that is separating the different flower types. for row 2-5 change the number of clusters you calculate from [1,2,3,4,5] and the numbers of initial random states you test [1,2,5,20]. Closely investigate the plots and formulate briefely where and when they differ.\n",
    "\n",
    "Now use the same code but only give it two of the 4 columns (e.g. the first two) and observe the difference. Can you formulate it?\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bfaaf2-e173-4a2f-9627-89549c678324",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)  # we start with the same random number to \n",
    "fig,ax=plt.subplots(5,5,figsize=(12,12))\n",
    "#plot the selection as given in the data \n",
    "selector_given=iris['target']\n",
    "for i in np.unique(selector_given):\n",
    "    selector_name=iris['target_names'][i]\n",
    "    for j in range(5):\n",
    "        ax[0,j].scatter(df_iris.iloc[selector_given==i,2],df_iris.iloc[selector_given==i,3],label=selector_name,s=2)\n",
    "\n",
    "#code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbac5de-253b-4ae0-921e-4f022b2158d3",
   "metadata": {},
   "source": [
    "# Choosing the right Clustering method\n",
    "\n",
    "try to separate the domains in all the images in the subfolder \"Smileys\" using the clustering methods: \n",
    "\n",
    "Kmean and spectral clustering from sklearn.cluster\n",
    "\n",
    "\n",
    "The domain image is from: \n",
    "Gorchy - Own work, CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=4459327\n",
    "\n",
    "Hint, for real images separating the clusters using an edge detection methoids can sometimes help. Here is a simple method for edge detection using the convolution with a simple Kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522a2ac1-a6c1-4e22-a810-71e42e9bcef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import misc,ndimage  # a library with useful stuff\n",
    "import skimage,cv2\n",
    "\n",
    "coins = skimage.data.coins()\n",
    "edges = cv2.Canny(coins, 100, 200)\n",
    "fig,ax=plt.subplots(1,2,figsize=(16,8))\n",
    "ax[0].imshow(coins, cmap='gray')\n",
    "ax[1].imshow(edges, cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
